{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(z):\n",
    "    #the sigmoid function is given by 1/(1+e^(-z))\n",
    "    return 1/(1+np.exp(-z)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(Y,a,X,m):\n",
    "    #Calculating the partial differential of the cost function with respect to the weight\n",
    "    #dw = -(1/m)*(y-a)*X, where a is the sigmoid of z\n",
    "    dw=-(1/m)*(np.dot(X, np.transpose(Y-a)))\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_bias(M,a,m):\n",
    "    #Calculating the partial differential of the cost function with respect to the bias\n",
    "    #b_new = -(1/m)*(y-a)*1\n",
    "    b_new=-(1/m)*np.sum(M-a)\n",
    "    return b_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(Y,predicted_val):\n",
    "    Y_int=Y.astype(int) #converting the float values of y into integer\n",
    "    Y_list=Y_int[0] #obtaining elements in the form of elements in a list (Y is in ndarray form)\n",
    "    pred=[int(i) for i in predicted_val] #list comprehension to get the int values from string data type\n",
    "    TP=0\n",
    "    FN=0\n",
    "    TN=0\n",
    "    FP=0\n",
    "    for i in range(len(Y_list)):\n",
    "        if (Y_list[i]==1) and (pred[i]==1): #TP = 1, if both the label value and predicted value are 1\n",
    "                TP=TP+1 \n",
    "        elif (Y_list[i]==1) and (pred[i]==0): #FN = 1, if the label value is 1 and predicted value is 0\n",
    "                FN=FN+1\n",
    "        elif (Y_list[i]==0) and (pred[i]==0): #TN = 1, if both the label value and predicted value are 0\n",
    "                TN=TN+1\n",
    "        elif (Y_list[i]==0) and (pred[i]==1): #FP = 1, if the label value is 0 and predicted value is 1\n",
    "            FP=FP+1\n",
    "    #calculating accuracy using (TP+TN)/(TP+TN+FP+FN)\n",
    "    accuracy=(TP+TN)/(TP+TN+FP+FN)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_func(a, Y, m):\n",
    "    #Calculating the cost of the model\n",
    "    #cost = -(1/m)summation((Y*log(a)+(1-Y)*log(1-a)))\n",
    "    cost = -(1/m)*(np.sum(Y*np.log(a)+(1-Y)*np.log(1-a))) \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_precision(Y,predicted_val):\n",
    "    Y_int=Y.astype(int) \n",
    "    Y_list=Y_int[0] \n",
    "    pred=[int(i) for i in predicted_val] \n",
    "    TP=0\n",
    "    FP=0\n",
    "    for i in range(len(Y_list)):\n",
    "        if (Y_list[i]==1) and (pred[i]==1):\n",
    "                TP=TP+1 \n",
    "        elif (Y_list[i]==0) and (pred[i]==1):\n",
    "                FP=FP+1\n",
    "    #calculating the precision using the formula (TP)/(TP+FP)\n",
    "    precision = TP/(TP+FP)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_recall(Y,predicted_val):\n",
    "    Y_int=Y.astype(int)\n",
    "    Y_list=Y_int[0] \n",
    "    pred=[int(i) for i in predicted_val] \n",
    "    TP=0\n",
    "    FN=0\n",
    "    for i in range(len(Y_list)):\n",
    "        if (Y_list[i]==1) and (pred[i]==1):\n",
    "                TP=TP+1\n",
    "        elif (Y_list[i]==1) and (pred[i]==0):\n",
    "                FN=FN+1\n",
    "    #calculating recall using the formula (TP)/(TP+FN)\n",
    "    recall = TP/(TP+FN)\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score1(Y,predicted_val):\n",
    "    prec_val = model_precision(Y,predicted_val)\n",
    "    recall_val = model_recall(Y,predicted_val)\n",
    "    g=1/prec_val\n",
    "    f=1/recall_val\n",
    "    #Calculating f1 score using the formula 2/((1/precision)+(1/recall))\n",
    "    f1_score_val=2/(g+f)\n",
    "    return f1_score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_eval(test,w_final,b_final):\n",
    "    #creating the label for test data\n",
    "    test_label = np.array(test[1]) # Y is of the data type - numpy.ndarray\n",
    "    shape=(1, 57) \n",
    "    test_label = test_label.reshape(shape)\n",
    "    \n",
    "    #dropping the label from the test dataset\n",
    "    test.drop(test.columns[0],axis=1, inplace=True) #removing the label #you have to re-run the code to eliminate key error. restart the kernels\n",
    "    test = test.T\n",
    "    \n",
    "    #Calculating the basis equation\n",
    "    z_test=np.array(np.dot(w_final.T,test)+b_final)\n",
    "    \n",
    "    #calculating the sigmoid of the basis equation\n",
    "    a_test=sig(z_test)\n",
    "    \n",
    "    #calculating the predicted_val of X\n",
    "    predicted_val_test=[]\n",
    "    for x in np.nditer(a_test):\n",
    "        if x>=0.5:\n",
    "            predicted_val_test.append('1')\n",
    "        else:\n",
    "            predicted_val_test.append('0')\n",
    "    \n",
    "    #Calculating the accuracy, precision and recall of the test set\n",
    "    accuracy_obtained_test = model_accuracy(test_label,predicted_val_test)\n",
    "    print(\"Applying key metrics on test data\")\n",
    "    print(\"Accuracy of test data: \",accuracy_obtained_test)\n",
    "    precision_test = model_precision(test_label,predicted_val_test)\n",
    "    print(\"Precision of test data: \",precision_test)\n",
    "    recall_test = model_recall(test_label,predicted_val_test)\n",
    "    print(\"Recall of test data: \",recall_test)\n",
    "    f1_score_value= f1_score1(test_label,predicted_val_test)\n",
    "    print(\"F1 score of test data: \",f1_score_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(a):\n",
    "    predicted_value=[]\n",
    "    for x in np.nditer(a):\n",
    "        if x>=0.5:\n",
    "            predicted_value.append('1')\n",
    "        else:\n",
    "            predicted_value.append('0')\n",
    "    return predicted_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cancer_types = {\"B\":0,\"M\":1}\n",
    "\n",
    "#step 1 : read the csv file [works]\n",
    "\n",
    "my_dataset=pd.read_csv(\"ml_dataset.csv\",header=None)\n",
    "#type(my_dataset)\n",
    "#del my_dataset['0']\n",
    "\n",
    "#step 2 : dropping the first column and replacing the M & B with 0 and 1 [works]\n",
    "\n",
    "my_dataset1=pd.DataFrame(my_dataset)\n",
    "my_dataset1.drop(my_dataset1.columns[0],axis=1, inplace=True)\n",
    "my_dataset1.replace({my_dataset1.columns[0]:cancer_types},inplace=True)\n",
    "\n",
    "#step 3: normalization min-max [works]\n",
    "\n",
    "norm=my_dataset1.copy()\n",
    "for features in my_dataset1.columns:\n",
    "    max_value=my_dataset1[features].max()\n",
    "    min_value=my_dataset1[features].min()\n",
    "    norm[features]=(my_dataset1[features]-min_value)/(max_value-min_value)   \n",
    "norm\n",
    "\n",
    "#step 4 : splitting data into training, validation and testing [works]. Split the data into 80%,10%,10%\n",
    "\n",
    "X, validate, test = np.split(norm.sample(frac=1), [int(.8*len(norm)), int(.9*len(norm))])\n",
    "#shapes of {X= (455,31), validate = (57,31), test = (57,31) \n",
    "\n",
    "\n",
    "#step 5 : We have now extracted the label column from the X dataset and stored it in Y, which is then reshaped to give the right shape.\n",
    "\n",
    "Y = np.array(X[1]) # Y is of the data type - numpy.ndarray\n",
    "#Y.shape = (455,)\n",
    "shape=(1, 455) \n",
    "Y = Y.reshape(shape)\n",
    "#Y.shape = (1,455)\n",
    "\n",
    "\n",
    "#step 6: We have now extracted the label column from the Validate dataset and stored it in validate_label, which is then reshaped to give the right shape.\n",
    "        \n",
    "validate_label=np.array(validate[1])\n",
    "shape1=(1,57)\n",
    "validate_label=validate_label.reshape(shape1)\n",
    "#validate_label.shape = 1,57\n",
    "\n",
    "\n",
    "#step 7 : Dropping the label column from the X data set\n",
    "X.drop(X.columns[0],axis=1, inplace=True) #removing the label\n",
    "X = X.T\n",
    "#X.shape = (30, 455)\n",
    "\n",
    "#step 8: dropping the label column from the validate set\n",
    "validate.drop(validate.columns[0],axis=1,inplace=True)\n",
    "validate=validate.T\n",
    "#validate.shape = 30,57\n",
    "\n",
    "\n",
    "#step 9 : Initializing weights, bias and learning factor\n",
    "\n",
    "w = np.zeros((X.shape[0], 1))\n",
    "#w.shape = (30,1)\n",
    "b=0 #bias is equal to 0\n",
    "n=0.1 #n is the learning rate\n",
    "m=X.shape[1] #no. of samples. m is the no. of samples for X\n",
    "\n",
    "u=validate.shape[1] #u.shape() = 57 #u is the no. of samples in validate\n",
    "\n",
    "\n",
    "#step 10 : Iteration begins \n",
    "training_accuracy = []\n",
    "loss=[]\n",
    "loss_validate=[]\n",
    "validate_accuracy=[]\n",
    "for epoch in range(10000):\n",
    "    \n",
    "    #calculating the basis function of X and validate\n",
    "    z1=np.array(np.dot(w.T,X)+b)\n",
    "    z_validate=np.array(np.dot(w.T,validate)+b)\n",
    "    \n",
    "\n",
    "    #calculating the sigmoid function of X and validate\n",
    "    a=sig(z1)\n",
    "    a_validate=sig(z_validate)\n",
    "    \n",
    "    #calculating the predicted_val of X\n",
    "    predicted_val=predict(a)\n",
    "    predicted_val_data=predict(a_validate)\n",
    "           \n",
    "    #calculating the accuracy of both X & validation data\n",
    "    accuracy_obtained = model_accuracy(Y,predicted_val)\n",
    "    accuracy_validate = model_accuracy(validate_label,predicted_val_data)\n",
    "    \n",
    "    #appending the accuracy of X and validation data to a list for plotting purpose\n",
    "    training_accuracy.append(accuracy_obtained)\n",
    "    validate_accuracy.append(accuracy_validate)\n",
    "    \n",
    "    #calculating the cost of X and validate\n",
    "    cost2=cost_func(a,Y,m) #cost func of X\n",
    "    cost_validate = cost_func(a_validate,validate_label,u) #cost func of validate\n",
    "    \n",
    "    #calculating the weights and training the model\n",
    "    w=w-n*gradient(Y,a,X,m) #calculating the new value of w using the formula for updation of weights => w=w-(n*gradient(weight)\n",
    "    b=b-n*gradient_bias(Y,a,m) #updating the bias term\n",
    "    \n",
    "    #lists of the X and validate cost function\n",
    "    loss.append(cost2) #list of X cost\n",
    "    loss_validate.append(cost_validate) #list of validate cost\n",
    "    \n",
    "\n",
    "#weight for test data\n",
    "w_final=w\n",
    "b_final=b\n",
    "\n",
    "#to plot the epochs\n",
    "i=0\n",
    "epochs=[]\n",
    "for i in range(10000):\n",
    "    i=i+1\n",
    "    epochs.append(i)\n",
    "    \n",
    "#plotting the training accuracy vs number of epochs\n",
    "plt.plot(epochs,training_accuracy,'r')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Training accuracy')\n",
    "plt.title('Variation of training accuracy with respect to epochs')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs,validate_accuracy,'b')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.title('Variation of validation accuracy with respect to epochs')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs,loss,'r')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Cost of training data')\n",
    "plt.title('Variation of cost with respect to epochs')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs,loss_validate,'b')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Cost of validation data')\n",
    "plt.title('Variation of cost with respect to epochs')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#evaluates the key metrics of the test data\n",
    "test_data_eval(test,w_final,b_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
